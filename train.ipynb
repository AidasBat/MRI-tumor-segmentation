{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061a42fd-7128-4966-b9ea-5c12df7c1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from unet import unet\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # tf log messages suppression\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f703e6f-fd32-437d-ba9e-f7ba0367d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "H = 256\n",
    "W = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d69bbfd-d5c3-4476-8ddf-262538be2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\batvi\\MRI-tumor-segmentation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26f0c1b-5e56-4288-9676-e3366954768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-15):\n",
    "    \"\"\"\n",
    "    Compute the Dice Coefficient for image segmentation tasks.\n",
    "    \n",
    "    Args:\n",
    "        y_true (tensor): Ground truth mask.\n",
    "        y_pred (tensor): Predicted mask.\n",
    "        smooth (float): Smoothing factor to avoid division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        tensor: Dice coefficient score.\n",
    "    \"\"\"\n",
    "    # Flatten the tensors\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    \n",
    "    # Compute the intersection\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    # Compute the Dice coefficient\n",
    "    dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the Dice Loss, which is 1 - Dice Coefficient.\n",
    "    \n",
    "    Args:\n",
    "        y_true (tensor): Ground truth mask.\n",
    "        y_pred (tensor): Predicted mask.\n",
    "    \n",
    "    Returns:\n",
    "        tensor: Dice loss value.\n",
    "    \"\"\"\n",
    "    return 1.0 - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b433b6-0247-4989-88c0-e8b01d9c7a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    }
   ],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path, split=0.2): # 60% for training, 20% for validation, 20% for testing\n",
    "    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
    "    #print(images[0], masks[0])\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "\n",
    "    # x refers to images and y refers to masks\n",
    "    train_x, valid_x = train_test_split(images, test_size = split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size = split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size = split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size = split_size, random_state=42)\n",
    "\n",
    "    return(train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "    # 60% for training, 20% for validation, 20% for testing\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0 # normalization with max pixel range\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x / 255.0 # normalization with max pixel range - white part of the mask becomes 1 instead of 255.0\n",
    "    x = x.astype(np.float32) # (h, w)\n",
    "    x = np.expand_dims(x, axis=-1) # (h, w, 1)\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y): # takes single image path and single mask path\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2): # X is a list of image file paths (and Y is list of mask paths)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(10)\n",
    "    return dataset\n",
    "                         \n",
    "if __name__ == \"__main__\":\n",
    "    # Seeding\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # Directory for storing files\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    batch_size = 16\n",
    "    lr = 1e-4\n",
    "    num_epochs = 60\n",
    "    model_path = os.path.join(\"files\", \"model.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
    "\n",
    "    # Dataset\n",
    "    dataset_path = r\"C:\\Users\\batvi\\MRI-tumor-segmentation\\Dataset\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n",
    "    #for x, y in train_dataset:\n",
    "        #print(x.shape, y.shape)\n",
    "\n",
    "    # Model\n",
    "    model = unet((H,W, 3))\n",
    "    model.compile(loss = dice_loss, optimizer = Adam(lr), metrics = [dice_coefficient])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, save_best_only=True, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs = num_epochs,\n",
    "        validation_data = valid_dataset,\n",
    "        callbacks = callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfa9f0-5a11-4dee-bb11-de058dc674ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870d413-a58e-44bd-9a75-9c435d03566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5f078-9905-4d09-8099-eaf9a9dfadd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d921f0-8ed0-44d6-8823-a78d3ef1e7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3259c-8613-4418-90c9-b9f3e1c739cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
